<!DOCTYPE html>
<html>
  <head><meta name="generator" content="Hexo 3.8.0">
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="theme-color" content="#33363b">
    <meta name="msapplication-TileColor" content="#33363b">
    
    
    
    
    <meta name="keywords" content="Life, ARIA, erow">
    
    
    <link rel="apple-touch-icon" sizes="180x180" href="/favicons/apple-touch-icon.png">
    
    
    <link rel="icon" type="image/png" sizes="192x192" href="/favicons/android-chrome-192x192.png">
    
    
    <link rel="icon" type="image/png" sizes="32x32" href="/favicons/favicon-32x32.png">
    
    
    <link rel="icon" type="image/png" sizes="16x16" href="/favicons/favicon-16x16.png">
    
    
    <link rel="mask-icon" href="/favicons/safari-pinned-tab.svg" color="#33363b">
    
    
    <link rel="manifest" href="/favicons/site.webmanifest">
    
    
    <meta name="msapplication-config" content="/favicons/browserconfig.xml">
    
    
    <link rel="alternate" href="/atom.xml" title="erow's blog" type="application/atom+xml">
    
    
    <link rel="shortcut icon" type="image/x-icon" href="/favicons/favicon.ico">
    
    
    <link rel="stylesheet" type="text/css" href="/css/normalize.css">
    <link rel="stylesheet" type="text/css" href="/css/index.css">
    
    <link rel="stylesheet" type="text/css" href="/css/sidebar.css">
    
    
<link rel="stylesheet" type="text/css" href="/css/page.css">
<link rel="stylesheet" type="text/css" href="/css/post.css">

    <link rel="stylesheet" type="text/css" href="/css/custom.css">
    <link rel="stylesheet" type="text/css" href="/css/solarized-light.css">
    <link rel="stylesheet" type="text/css" href="/css/lightgallery.min.css">
    <script type="text/javascript" src="/js/jquery.min.js"></script>
    <script defer type="text/javascript" src="/js/util.js"></script>
    <script defer type="text/javascript" src="/js/scrollspy.js"></script>
    <script defer type="text/javascript" src="/js/fontawesome-all.min.js"></script>
    <script defer type="text/javascript" src="/js/lightgallery.min.js"></script>
    <script defer type="text/javascript" src="/js/lg-fullscreen.min.js"></script>
    <script defer type="text/javascript" src="/js/lg-hash.min.js"></script>
    <script defer type="text/javascript" src="/js/lg-pager.min.js"></script>
    <script defer type="text/javascript" src="/js/lg-thumbnail.min.js"></script>
    <script defer type="text/javascript" src="/js/lg-zoom.min.js"></script>
    
    <script defer src="/js/busuanzi.pure.mini.js"></script>
    
    
    <script defer type="text/javascript" src="/js/search.js"></script>
    <script type="text/javascript">
    $(document).ready(function () {
      var searchPath = "search.xml";
      if (searchPath.length === 0) {
        searchPath = "search.xml";
      }
      var path = "/" + searchPath;
      searchFunc(path, "search-input", "search-result");
    });
    </script>
    
    
    
    <script defer type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-MML-AM_CHTML"></script>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ["$","$"], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ["script", "noscript", "style", "textarea", "pre", "code"]
      }
    });
    </script>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for (i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += " has-jax";
      }
    });
    </script>
    
    
    <script defer type="text/javascript" src="/js/index.js"></script>
    
    <script defer type="text/javascript" src="/js/custom.js"></script>
    <title>erow's blog</title>
  </head>
  <body itemscope="" itemtype="http://schema.org/WebPage" lang="zh_CN" data-spy="scroll" data-target=".list-group">
    
<header id="header" class="header" style="background: #33363b;">
  <div class="container">
    <div class="header-container">
      <div class="header-title">
        <h1 class="title"><a href="/">erow's blog</a></h1>
        <h2 class="subtitle"></h2>
      </div>
      
      <div class="logo">
        <img src="/images/logo.png" alt="logo">
      </div>
      
    </div>
    <nav id="nav" class="nav">
      <a id="nav-toggle" class="nav-toggle" aria-hidden="true"><i class="fas fa-bars" aria-label="切换导航栏"></i></a>
      <ul id="menu" role="menubar" aria-hidden="false">
        
        <li role="menuitem"><a href="/">首页</a></li>
        
        <li role="menuitem"><a href="/archives/">归档</a></li>
        
        <li role="menuitem"><a href="/categories/">分类</a></li>
        
        <li role="menuitem"><a href="/tags/">标签</a></li>
        
      </ul>
    </nav>
  </div>
</header>


    <main id="main" class="main">
      <div class="container">
        <div class="main-container" style="background: url(/images/background.png);">
          <div class="content">
            

<div id="index" class="index page">
  
  <article class="article post card animate" itemscope="" itemtype="http://schema.org/Article">
    <div class="post-block">
      <link itemprop="mainEntityOfPage" href="http://erow.github.io/2019/02/13/2019/CNN/">
      <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
        <meta itemprop="name" content="erow">
        <meta itemprop="description" content="">
        <meta itemprop="image" content="/images/avatar.jpg">
      </span>
      <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
        <meta itemprop="name" content="erow's blog">
      </span>
    </div>
    <header class="post-header">
      <h1 class="post-title" itemprop="name headline">
        <a class="post-title-link post-title-link-external" href="/2019/02/13/2019/CNN/" itemprop="url">lenet5</a>
      </h1>
      <div class="post-meta">
        
        <span class="post-date">
          <i class="far fa-calendar-plus"></i><span><time title="post-date" itemprop="dateCreated datePublished" datetime="2019-02-13T14:13:54+08:00">2019-02-13 14:13:54</time></span>
        </span>
        
        
        
        <span class="post-meta-divider divider">|</span>
        
        <span class="post-categories">
          
          <i class="far fa-folder-open"></i><span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/ML/" itemprop="url" rel="index"><span itemprop="name">ML</span></a></span>
        </span>
        
        
        
        
      </div>
    </header>
    <main class="post-main" itemprop="articleBody">
      
      <p><a href="http://yann.lecun.com/exdb/lenet/" target="_blank" rel="noopener">lenet5</a> 实现了手写数字的识别。其关键在于CNN的使用。其结构如下：</p>
<p><img src="/blog_images/2019-02-18-09-49-21.png" alt="">  </p>
<h1 id="convolution"><a href="#convolution" class="headerlink" title="convolution"></a>convolution</h1><p><a href="https://www.matongxue.com/madocs/32.html" target="_blank" rel="noopener">通俗地理解卷积运算</a> 数学表达式：<br>$$ (f<em>g)(x) = \int_{-\infty}^\infty f(\tau)g(x-\tau)d\tau $$<br>可以把$f(x)$理解为信号，$g(x)$理解为发出信号的时机。那么卷积就代表了当前时刻该信号的叠加效果。<a href="https://zhuanlan.zhihu.com/p/30994790" target="_blank" rel="noopener">在图像中卷积的意义</a>。虽然卷积的过程看上去很像内积，但其实两者有很大的区别，两者的前进方向不同。为了方便计算，将g中的下标进行修改，使得卷积运算可以直接用内积来表示。(将g旋转$180\degree$)<br><img src="/blog_images/2019-02-13-19-04-01.png" alt=""><br>卷积后得到的矩阵称为<strong>feature map</strong><br><img src="https://mlnotebook.github.io/img/CNN/convSobel.gif" alt=""><br>如果特征刚好在角落上，那么上面的卷积过程无法检测到。因此，可以在输入矩阵上填充<strong>padding</strong>。同时使得输入与输出的大小相同。 <img src="https://mlnotebook.github.io/img/CNN/convZeros.png" alt="Zero-padding is used so that the resulting image doesn&#39;t shrink."><br>也可以控制<strong>stride</strong>来改变卷积核的移动步伐.这会导致<strong>feature map</strong>的尺寸变小。<br>设输入的尺寸为 $I_r \times I_c$ , 卷积核尺寸为$K_r \times K_c$, 则可训练参数为$K_r</em>K_c+1$,输出尺寸为$(I_r+1-K_r) \times (I_c+1-K_c)$.(无padding，stride=1)</p>
<h2 id="Convolutional-Layer"><a href="#Convolutional-Layer" class="headerlink" title="Convolutional Layer"></a>Convolutional Layer</h2><p>作为神经网络，每一个节点只有2种状态（激活或者未激活）。在感知机中使用sigmoid函数进行激活使得输出值在[0,1]。这一过程被称为<strong>Non-linearity</strong>。</p>
<h1 id="Pooling-Layer"><a href="#Pooling-Layer" class="headerlink" title="Pooling Layer"></a>Pooling Layer</h1><p>这一过程比较简单，它将原图像进行分割。再对每一个区域进行一次计算。与卷积不同的是，这里的每一块区域都是不重叠的。最终它使得输入尺寸成倍地减少。这一操作称为<strong>subsampling</strong> <img src="https://mlnotebook.github.io/img/CNN/poolfig.gif" alt="Max-pooling: Pooling using a &quot;max&quot; filter with stride equal to the kernel size"><br>每一层含有2个参数，<strong>coefficient and bias</strong>。同样，作为神经网络中的一层，需要对<strong>subsampling</strong>后的数乘以<strong>coefficient</strong>+<strong>bias</strong> 再用sigmoid函数激活才能输出到网络中。</p>
<h1 id="Fully-connected-Dense-Layer"><a href="#Fully-connected-Dense-Layer" class="headerlink" title="Fully-connected (Dense) Layer"></a>Fully-connected (Dense) Layer</h1><p>这一层与多层神经网络相同，不同的是它的输入可能具有多个<strong>channel</strong>。不管怎么样，都可以将输入看作是一维的。</p>
<h1 id="Practice"><a href="#Practice" class="headerlink" title="Practice"></a>Practice</h1><p>这里我遵照lenet5原始论文进行复现。<a href="http://yann.lecun.com/exdb/mnist/" target="_blank" rel="noopener">材料:数据集+论文</a></p>
<h2 id="预处理"><a href="#预处理" class="headerlink" title="预处理"></a>预处理</h2><p>背景色置为-0.1，前景色为1.175. <code>(raw-20)/200</code></p>
<h2 id="C1"><a href="#C1" class="headerlink" title="C1"></a>C1</h2><p>这里有点奇怪，论文里说输入图像是32X32的，但是数据集是28X28的。<br>6个 <strong>zero-padding</strong>5X5的卷积层。有$6<em>5</em>5+6(bias)=156$个参数。$6<em>28</em>28=4704$个神经元。<br>输出：$6\times28\times28$</p>
<h2 id="S2"><a href="#S2" class="headerlink" title="S2"></a>S2</h2><p>大小为：2X2.取区域平均值×系数+bias再sigmoid激活。 参数：$6\times 2$<br>输出：$6\times14\times14$</p>
<h2 id="C3"><a href="#C3" class="headerlink" title="C3"></a>C3</h2><p>这里卡了很久，不知道多个feature map 如何进行卷积。其实可以把多个feature map当作多个通道，每个通道上各自进行卷积再叠加在一起。或者说这个卷积具有3维结构（前面都是二维的），只不过其中一维的大小为3，因此正好被压回2维结构。3X14X14的输入，3X5X5的核。<br><img src="/blog_images/2019-02-18-09-47-33.png" alt=""><br>参数：3X5X5 6个，4X5X5 6+3个，6X5X5 1个<br>输出：16X10X10</p>
<h2 id="S4"><a href="#S4" class="headerlink" title="S4"></a>S4</h2><p>大小为：2X2.取区域平均值×系数+bias再sigmoid激活。<br>输出：$16\times5\times5$</p>
<h2 id="C5"><a href="#C5" class="headerlink" title="C5"></a>C5</h2><p>大小为：16X5X5. 共120个。<br>输出：120X1</p>
<h2 id="F6"><a href="#F6" class="headerlink" title="F6"></a>F6</h2><p>使用正切函数激活。<br>$$ f(a)=A tanh(S*a) $$<br>A为1.7159.<br>输出：84</p>
<h2 id="output"><a href="#output" class="headerlink" title="output"></a>output</h2><p>计算公式：<br>$$ y_i=\sum_j(x_j-w_{ij})^2 $$<br>如果模型有k个输出，即k个分类。那么$w_{k*}$代表了该类别在特征空间中的位置。显然，离该特征向量越远，输出越大。这称为<strong>distributed code</strong></p>
<h2 id="Loss-function"><a href="#Loss-function" class="headerlink" title="Loss function"></a>Loss function</h2><h2 id="关键代码"><a href="#关键代码" class="headerlink" title="关键代码"></a>关键代码</h2><p>写了一通代码发现直接炸了，运算速度实在太慢，简直出不了结果。实验了一下发现python的for循环效率极低，要实现神经网络，必须全部使用专门优化过的工具。如numpy，最好全程使用矩阵运算并避免矩阵的复制。使用卷积的时候可以利用<a href="https://blog.csdn.net/dwyane12138/article/details/78449898" target="_blank" rel="noopener">im2col</a><br><figure class="hljs highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs undefined">def use_time(f,c=<span class="hljs-number">1</span>,*<span class="hljs-built_in">args</span>):<br>    import datetime<br>    start = datetime.datetime.now()<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(c):<br>        f(*<span class="hljs-built_in">args</span>)<br>    <span class="hljs-built_in">return</span> datetime.datetime.now()-start<br><br>def im2col(<span class="hljs-built_in">image</span>, ksize, stride):<br>    # <span class="hljs-number">100</span> , <span class="hljs-number">5</span>,<span class="hljs-number">1</span>  <span class="hljs-number">0</span>:<span class="hljs-number">00</span>:<span class="hljs-number">12.587087</span><br>    # <span class="hljs-built_in">image</span> <span class="hljs-built_in">is</span> a 4d tensor([batchsize, <span class="hljs-built_in">width</span> ,<span class="hljs-built_in">height</span>, channel])<br>    image_col = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-built_in">image</span>.shape[<span class="hljs-number">1</span>] - ksize + <span class="hljs-number">1</span>, stride):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-built_in">image</span>.shape[<span class="hljs-number">2</span>] - ksize + <span class="hljs-number">1</span>, stride):<br>            <span class="hljs-built_in">col</span> = <span class="hljs-built_in">image</span>[:, i:i + ksize, j:j + ksize, :].reshape([-<span class="hljs-number">1</span>])<br>            image_col.<span class="hljs-built_in">append</span>(<span class="hljs-built_in">col</span>)<br>    image_col = <span class="hljs-built_in">np</span>.<span class="hljs-built_in">array</span>(image_col)<br>    <span class="hljs-built_in">return</span> image_col<br><br>def im2col1(<span class="hljs-built_in">image</span>, ksize, stride):<br>    # <span class="hljs-number">0</span>:<span class="hljs-number">00</span>:<span class="hljs-number">02</span><br>    shape_r =(<span class="hljs-built_in">image</span>.shape[<span class="hljs-number">0</span>] - ksize + <span class="hljs-number">1</span>)//stride<br>    shape_c =(<span class="hljs-built_in">image</span>.shape[<span class="hljs-number">1</span>] - ksize + <span class="hljs-number">1</span>)//stride<br>    channel=<span class="hljs-built_in">image</span>.shape[<span class="hljs-number">3</span>]<br>    m = <span class="hljs-built_in">image</span>.shape[<span class="hljs-number">0</span>]<br>    <span class="hljs-built_in">col</span> = <span class="hljs-built_in">np</span>.zeros([shape_r*shape_c,ksize*ksize*channel*m])<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(shape_r):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(shape_c):<br>            <span class="hljs-built_in">col</span>[shape_r*i+j,:] = <span class="hljs-built_in">image</span>[:, i:i + ksize, j:j + ksize, :].reshape([-<span class="hljs-number">1</span>])<br>    <span class="hljs-built_in">return</span> <span class="hljs-built_in">col</span><br><br>def im2col2(<span class="hljs-built_in">image</span>, ksize, stride):<br>    # <span class="hljs-number">100</span> , <span class="hljs-number">5</span>,<span class="hljs-number">1</span>  <span class="hljs-number">0</span>:<span class="hljs-number">00</span>:<span class="hljs-number">12.587087</span><br>    # <span class="hljs-built_in">image</span> <span class="hljs-built_in">is</span> a 4d tensor([batchsize, <span class="hljs-built_in">width</span> ,<span class="hljs-built_in">height</span>, channel])<br>    image_col = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-built_in">image</span>.shape[<span class="hljs-number">1</span>] - ksize + <span class="hljs-number">1</span>, stride):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-built_in">image</span>.shape[<span class="hljs-number">2</span>] - ksize + <span class="hljs-number">1</span>, stride):<br>            <span class="hljs-built_in">col</span> = <span class="hljs-built_in">image</span>[:, i:i + ksize, j:j + ksize, :].reshape([-<span class="hljs-number">1</span>])<br>            image_col.<span class="hljs-built_in">append</span>(<span class="hljs-built_in">col</span>)<br><br>    <span class="hljs-built_in">return</span> <span class="hljs-built_in">np</span>.concatenate(image_col)<br><br>images=<span class="hljs-built_in">np</span>.<span class="hljs-built_in">random</span>.rand(<span class="hljs-number">10</span>,<span class="hljs-number">100</span>,<span class="hljs-number">100</span>,<span class="hljs-number">6</span>)<br><br><span class="hljs-built_in">print</span>(use_time(im2col,<span class="hljs-number">100</span>,images,<span class="hljs-number">5</span>,<span class="hljs-number">1</span>))<br><span class="hljs-built_in">print</span>(use_time(im2col1,<span class="hljs-number">100</span>,images,<span class="hljs-number">5</span>,<span class="hljs-number">1</span>))<br><span class="hljs-built_in">print</span>(use_time(im2col2,<span class="hljs-number">100</span>,images,<span class="hljs-number">5</span>,<span class="hljs-number">1</span>))<br></code></pre></td></tr></table></figure></p>
<h1 id="Appendix"><a href="#Appendix" class="headerlink" title="Appendix"></a>Appendix</h1><h2 id="implement"><a href="#implement" class="headerlink" title="implement"></a>implement</h2><p><a href="https://zhuanlan.zhihu.com/p/29716516" target="_blank" rel="noopener">参考实现</a></p>
<h2 id="sigmoid"><a href="#sigmoid" class="headerlink" title="sigmoid"></a>sigmoid</h2><p><a href="https://en.wikipedia.org/wiki/Sigmoid_function" target="_blank" rel="noopener">wiki</a><br>它是一类具有形如”S”的函数。常指Logistic function</p>
<h2 id="BP"><a href="#BP" class="headerlink" title="BP"></a>BP</h2><p><a href="https://blog.csdn.net/qq_21190081/article/details/72871704" target="_blank" rel="noopener">Pooling池化操作的反向梯度传播</a><br>在计算卷积的偏导数时，可以先把不同单元的权值当作是不同的分开计算，最后再把他们加起来。这就好比分身术，先产生n个分身，然后分身再合体回一个。它其实就是一个全微分：<br>$$ df(x_1,x_2)=f’<em>{x1} d</em>{x1}+f’<em>{x2}d</em>{x2} $$<br>如果令$x_1=x_2=x$就得到了上面的方法。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      </p>

      
    </main>
    <footer class="post-footer">
      
      <div class="post-tags">
        
        <a class="post-tag button" href="/tags/ML/" rel="tag"><i class="fas fa-tags"></i>ML</a>
        
        <a class="post-tag button" href="/tags/cnn/" rel="tag"><i class="fas fa-tags"></i>cnn</a>
        
      </div>
      
    </footer>
  </article>
  
  <article class="article post card animate" itemscope="" itemtype="http://schema.org/Article">
    <div class="post-block">
      <link itemprop="mainEntityOfPage" href="http://erow.github.io/2019/02/12/2019/SVM/">
      <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
        <meta itemprop="name" content="erow">
        <meta itemprop="description" content="">
        <meta itemprop="image" content="/images/avatar.jpg">
      </span>
      <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
        <meta itemprop="name" content="erow's blog">
      </span>
    </div>
    <header class="post-header">
      <h1 class="post-title" itemprop="name headline">
        <a class="post-title-link post-title-link-external" href="/2019/02/12/2019/SVM/" itemprop="url">SVM</a>
      </h1>
      <div class="post-meta">
        
        <span class="post-date">
          <i class="far fa-calendar-plus"></i><span><time title="post-date" itemprop="dateCreated datePublished" datetime="2019-02-12T17:13:54+08:00">2019-02-12 17:13:54</time></span>
        </span>
        
        
        
        <span class="post-meta-divider divider">|</span>
        
        <span class="post-categories">
          
          <i class="far fa-folder-open"></i><span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/ML/" itemprop="url" rel="index"><span itemprop="name">ML</span></a></span>
        </span>
        
        
        
        
      </div>
    </header>
    <main class="post-main" itemprop="articleBody">
      
      <h1 id="基本问题"><a href="#基本问题" class="headerlink" title="基本问题"></a>基本问题</h1><p>在一个线性可分的训练集中，求一条直线将2类数据分开，并使得其间隔最大化。<br><img src="2019-02-12-17-30-04.png" alt=""><br>西瓜书P123.<br>$$ min \frac{1}{2}\left |  w\right |^2 $$<br>$$ s.t. y_i(w^\top x_i+b)\geqslant 1 ,\: i =1,…,m. $$<br>其中 $y_i=1$ 表示正例，$y_i=-1$表示负例。</p>
<h2 id="对偶问题"><a href="#对偶问题" class="headerlink" title="对偶问题"></a>对偶问题</h2><p>使用拉格朗日乘子法求得其等价的，也就是对偶问题：<br>$$ max \sum_{i=1}^m \alpha_i-\frac{1}{2} \sum_{i=1}^m\sum_{j=1}^m \alpha_i \alpha_j y_i y_j \mathbf{x_i^\top}\mathbf{x_j} $$<br>$$ s.t. \sum_{i=1}^m \alpha_i y_i=0,\: \alpha_i \geq 0 $$<br>n+1个参数的优化问题变成了m个参数的优化问题。<br>要完全理解SVM的计算，需要搞清楚下面两个问题：</p>
<ol>
<li>原问题如何计算？</li>
<li>对偶问题又如何改进计算？</li>
</ol>
<h2 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h2><p>实际数据并不总是线性可分。即使找到了一个严格可分的平面，也有可能导致过拟合。<br><img src="2019-02-12-18-21-51.png" alt=""><br>引入正则化后的SVM的损失函数（hinge损失）可以表示为：<br>$$ \min_\theta C\sum_{i=1}^m[y_i cost_1(\mathbf{\theta^\top x_i})+(1-y_i)cost_0(\mathbf{\theta^\top x_i})] + \frac{1}{2} \sum_{j=1}^m \theta_j^2$$<br>当$C$取无穷大时，等价于严格约束，即找到一条线性可分的直线；<br>当$C$取一个适当的值，可以排除一些不符合的数据。</p>
<p>较大的$C$的影响：Lower bias, high variance == small $\lambda$ 过拟合。<br>较小的$C$的影响：Higher bias,low variance == large $\lambda$ 欠拟合。</p>
<h2 id="Logistic-regression-vs-SVMs"><a href="#Logistic-regression-vs-SVMs" class="headerlink" title="Logistic regression vs. SVMs"></a>Logistic regression vs. SVMs</h2><pre><code>n = number of features , m = number of training examples 
If   n  is large (relative to   m  ): n&gt;&gt;m
    Use logistic regression, or SVM without a kernel (“linear kernel”) 
If   n  is small,     m  is intermediate: 
    Use SVM with Gaussian kernel 
If   n  is small,     m is large: 
    Create/add more features, then use logistic regression or SVM  without a kernel 
Neural network likely to work well for most of these secngs, but may be 
slower to train. 
</code></pre><p>高斯核的SVM模型复杂度能够随着数据集的增大而增大，但是随着数据增大计算量也快速地提高因此SVM最适合的范围为（n=1~1000, m=10~10000, Andrew）<a href="https://scikit-learn.org/stable/modules/svm.html" target="_blank" rel="noopener">scikit learn中SVM</a>的复杂度为$O(n_{features}<em>m_{samples}^2)$到$O(n_{features}</em>m_{samples}^3)$之间。</p>
<h2 id="核函数"><a href="#核函数" class="headerlink" title="核函数"></a>核函数</h2><p><img src="2019-02-12-21-11-21.png" alt="高斯核"><br>核函数使得在原特征空间中线性不可分的数据映射到线性可分的特征空间中。可以将训练数据当成标记$l$，如果$x$在$l$附近，那么$f(x,l)$趋于1。这样就能把样本x映射到m维的空间中。在这个空间里描述了样本$x$到各个方向的距离。运用SVM算法，可以选择出有效的支持向量（处在边界上的点）。</p>
<pre><code>import numpy as np
y = np.array([0])
X = np.array([[-6,-6]])
for i in range(-5,6):
    for j in range(-5,6):
        X = np.append(X,[[i,j]],axis=0)
        y = np.append(y,abs(i)&lt;=3 and abs(j)&lt;=3)

from sklearn import svm
clf = svm.SVC(gamma=&apos;scale&apos;)
clf.fit(X, y)
clf.support_vectors_
</code></pre><p>以上代码SVM在不同样本附近选取特征点，组成支持向量，而不是全部训练样本。 感觉SVM与KNN有一定的相似度。KNN是选择附近数目多的训练样本，而SVM则是对$x$附近的训练样本进行数值加权。</p>

      
    </main>
    <footer class="post-footer">
      
      <div class="post-tags">
        
        <a class="post-tag button" href="/tags/ML/" rel="tag"><i class="fas fa-tags"></i>ML</a>
        
        <a class="post-tag button" href="/tags/SVM/" rel="tag"><i class="fas fa-tags"></i>SVM</a>
        
      </div>
      
    </footer>
  </article>
  
  <article class="article post card animate" itemscope="" itemtype="http://schema.org/Article">
    <div class="post-block">
      <link itemprop="mainEntityOfPage" href="http://erow.github.io/2019/01/27/2019/Neural Network/">
      <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
        <meta itemprop="name" content="erow">
        <meta itemprop="description" content="">
        <meta itemprop="image" content="/images/avatar.jpg">
      </span>
      <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
        <meta itemprop="name" content="erow's blog">
      </span>
    </div>
    <header class="post-header">
      <h1 class="post-title" itemprop="name headline">
        <a class="post-title-link post-title-link-external" href="/2019/01/27/2019/Neural Network/" itemprop="url">Neural Network</a>
      </h1>
      <div class="post-meta">
        
        <span class="post-date">
          <i class="far fa-calendar-plus"></i><span><time title="post-date" itemprop="dateCreated datePublished" datetime="2019-01-27T10:13:54+08:00">2019-01-27 10:13:54</time></span>
        </span>
        
        
        
        <span class="post-meta-divider divider">|</span>
        
        <span class="post-categories">
          
          <i class="far fa-folder-open"></i><span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/ML/" itemprop="url" rel="index"><span itemprop="name">ML</span></a></span>
        </span>
        
        
        
        
      </div>
    </header>
    <main class="post-main" itemprop="articleBody">
      
      <h1 id="反向传播网络"><a href="#反向传播网络" class="headerlink" title="反向传播网络"></a>反向传播网络</h1><p>反向传播是神经网络中求最优参数的一个运用梯度下降算法的应用。<br><img src="/blog_images/NN.jpg" alt="简化模型"><br>这是我总结的简化后的神经网络的模型。一个layer表示一个隐层。具体的计算过程可以参见andrew的ML，这里采用的符号z,a也是依据课程的介绍。<br>$$<br> a_1^{(2)} = g(\Theta_{10}^{(1)}x_0 + \Theta_{11}^{(1)}x_1 + \Theta_{12}^{(1)}x_2 + \Theta_{13}^{(1)}x_3) \newline a_2^{(2)} = g(\Theta_{20}^{(1)}x_0 + \Theta_{21}^{(1)}x_1 + \Theta_{22}^{(1)}x_2 + \Theta_{23}^{(1)}x_3) \newline a_3^{(2)} = g(\Theta_{30}^{(1)}x_0 + \Theta_{31}^{(1)}x_1 + \Theta_{32}^{(1)}x_2 + \Theta_{33}^{(1)}x_3) \newline h_\Theta(x) = a_1^{(3)} = g(\Theta_{10}^{(2)}a_0^{(2)} + \Theta_{11}^{(2)}a_1^{(2)} + \Theta_{12}^{(2)}a_2^{(2)} + \Theta_{13}^{(2)}a_3^{(2)}) \newline $$<br> 在计算梯度的时候主要方法是 求偏导数和换元法。从上图可知$z$是连接不同层之间的节点。<br> 在计算导数的时候，采用Z作为参考点会简化计算。先换元，转换为关于$z$的表达式$J(z^l)$.可知$\frac{∂J(Θ)}{∂z^{l}} =\frac{∂J(Θ)}{∂z^{l+1}}\frac{∂z^{l+1}}{∂z^{l}}$. 而这一部分$\frac{∂z^{l+1}}{∂z^{l}}=Θ^{k^T}z^{l+1}.<em>g’(z^l)$正是反向传播的关键。 要求得参数的导数所需要的最后一步$\frac{∂z^{l+1}}{∂Θ^{l}_{ij}}=a^l_j$<br> 由于：<br> $$ g′(z^{l})=a^l.∗ (1−a^l)$$<br> 因此<br> $$\delta^l=\frac{∂z^{l+1}}{∂z^{l}}=Θ^{k^T}z^{l+1}.</em>a^l.∗ (1−a^l)$$<br> $$\frac{∂J}{∂Θ^{l}}=\delta^{l+1}a^{l^T}$$</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p> <a href="https://www.coursera.org/learn/machine-learning/supplement/Bln5m/model-representation-i" target="_blank" rel="noopener">Neural Networks: Learning</a></p>

      
    </main>
    <footer class="post-footer">
      
      <div class="post-tags">
        
        <a class="post-tag button" href="/tags/ML/" rel="tag"><i class="fas fa-tags"></i>ML</a>
        
        <a class="post-tag button" href="/tags/NN/" rel="tag"><i class="fas fa-tags"></i>NN</a>
        
      </div>
      
    </footer>
  </article>
  
  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/5/"><i class="fas fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><span class="page-number current">6</span><a class="page-number" href="/page/7/">7</a><span class="space">&hellip;</span><a class="page-number" href="/page/13/">13</a><a class="extend next" rel="next" href="/page/7/"><i class="fas fa-angle-right" aria-label="下一页"></i></a>
  </nav>
  
  
  

<div class="comments" id="comments">
  
  
  
</div>



  
</div>

          </div>
          
          
          
<aside class="sidebar" id="sidebar" style="">
  
  <div class="search">
    <div class="form-group">
      <i class="fas fa-search"></i><input type="search" id="search-input" name="q" results="0" placeholder="搜索" class="form-control">
    </div>
  </div>
  <div class="search-result-box" id="search-result"></div>
  
  
<div class="info sidebar-item" id="info">
  
  <img class="author-avatar" src="/images/avatar.jpg" alt="erow">
  
  <h1 class="author-name">erow</h1>
  <h2 class="author-description"></h2>
  <div class="site-count">
    
    <div class="archives-count">
      <div class="site-count-title">归档</div>
      <div><a href="/archives/">38</a></div>
    </div>
    
    
    
    <span class="site-count-divider divider">|</span>
    
    <div class="categories-count">
      <div class="site-count-title">分类</div>
      <div><a href="/categories/">9</a></div>
    </div>
    
    
    
    <span class="site-count-divider divider">|</span>
    
    <div class="tags-count">
      <div class="site-count-title">标签</div>
      <div><a href="/tags/">27</a></div>
    </div>
    
  </div>
  
  <div class="rss">
    <a class="rss-link button sidebar-item" href="/atom.xml"><i class="fas fa-rss"></i>RSS</a>
  </div>
  
</div>


  <div class="sidebar-sticky">
    
    
    <hr>
    <div class="social-link sidebar-item">
      <div><i class="far fa-address-card"></i>社交链接<p></p></div>
      <ul>
        
        <li><i class="fas fa-envelope"></i><a href="mailto:clouderow@gmail.com" target="_blank">E-Mail</a></li>
        
        <li><i class="fab fa-github"></i><a href="https://github.com/erow" target="_blank">GitHub</a></li>
        
      </ul>
    </div>
    
    
    <hr>
    <div class="blogroll sidebar-item">
      <div><i class="fas fa-link"></i>友情链接</div>
      <ul>
        
        <li><a href="" target="_blank">虚位以待</a></li>
        
      </ul>
    </div>
    
  </div>
</aside>


          
        </div>
      </div>
    </main>
    
<footer id="footer" class="footer" style="background: #33363b;">
  <div class="container">
    <div class="back-to-top">
      <button id="back-to-top"><i class="fas fa-angle-double-up" aria-label="回到顶部"></i></button>
    </div>
    <div class="footer-container">
      <div class="footer-left">
        <div class="copyright">
          <span class="author">erow</span><span class="year"><i class="far fa-copyright"></i>2019 - 2019</span><span class="creative-commons"><i class="fab fa-creative-commons"></i><a href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">BY-SA 4.0</a></span>
        </div>
        
        <div class="busuanzi">
          <span id="busuanzi_container_site_pv"><i class="fas fa-eye" aria-label="站点点击量" aria-hidden="false"></i><span id="busuanzi_value_site_pv"></span></span><span id="busuanzi_container_site_uv"><i class="fas fa-user" aria-label="站点用户数" aria-hidden="false"></i><span id="busuanzi_value_site_uv"></span></span><span id="busuanzi_container_page_pv"><i class="far fa-file-alt"></i><span id="busuanzi_value_page_pv" aria-label="页面点击量" aria-hidden="false"></span></span>
        </div>
        
      </div>
      <div class="footer-right">
        <div class="custom-info">
          
          托管于<i class="fab fa-github-alt"></i><a href="https://pages.github.com/" target="_blank">GitHub Pages</a>
          
        </div>
        <div class="powered-by">
          由 <a href="https://hexo.io/" target="_blank">Hexo</a> 强力驱动 | 主题 <a href="https://github.com/AlynxZhou/hexo-theme-aria/" target="_blank">ARIA</a>
        </div>
      </div>
    </div>
  </div>
</footer>


  </body>
</html>
